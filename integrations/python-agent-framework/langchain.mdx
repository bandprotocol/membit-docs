---
title: "LangChain"
description: "Integrate Membit's real-time social context into your LangChain agents and applications using MCP tools."
icon: "langchain"
---

Enhance your LangChain applications with real-time social media context from Membit. This integration allows your AI agents to access up-to-the-minute discussions, trends, and insights from platforms like X (Twitter), Farcaster, and more.

## Prerequisites

Before you begin, ensure you have:

- Python 3.10 or higher installed
- A Membit account with API access
- Basic familiarity with LangChain agents
- Node.js installed (for MCP remote client)

<Warning>
You'll need valid Membit API credentials and the MCP remote URL. If you don't have access yet, [get your API key](/access-and-auth) to get started.
</Warning>

## Installation

Install the required packages for LangChain and MCP integration:

```bash
# Install LangChain MCP adapter
pip install langchain-mcp-adapters

# Install MCP remote client (requires Node.js)
npm install -g mcp-remote
```

<Tip>
We recommend using a virtual environment to manage your Python dependencies and avoid conflicts.
</Tip>

## Quick Start

<Steps>
<Step title="Import required modules">
Import the necessary components for LangChain and MCP integration:

```python
import asyncio

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema import HumanMessage
from langchain_mcp_adapters.tools import load_mcp_tools
```
</Step>

<Step title="Configure your LLM">
Set up your language model with the provider of your choice:

```python
llm = init_chat_model(
    model="gpt-4o",
    model_provider="openai",
)
```
</Step>

<Step title="Configure MCP server parameters">
Set up the connection to Membit's MCP server:

```python
server_params = StdioServerParameters(
    command="npx",
    args=[
        "mcp-remote",
        "https://mcp.membit.ai/mcp/?Membit-Api-Key=<your-api-key>",
    ],
)
```

<Note>
Make sure you have `mcp-remote` installed globally via npm for this to work.
</Note>

<Warning>
Replace `<your-api-key>` with your actual Membit API key. Keep this credential secure and don't share it with unauthorized users.
</Warning>
</Step>

<Step title="Create agent prompt">
Define a prompt template that encourages the agent to use Membit tools:

```python
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Make sure you utilize membit tools to get the most trending data."
        ),
        MessagesPlaceholder(variable_name="messages"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ]
)
```
</Step>

<Step title="Create and run your agent">
Connect to Membit and create your LangChain agent:

```python
async def main():
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # Initialize the MCP connection
            await session.initialize()

            # Load Membit tools from MCP session
            mcp_tools = await load_mcp_tools(session)

            # Create the LangChain agent
            agent = create_openai_tools_agent(
                llm=llm, 
                tools=mcp_tools, 
                prompt=prompt
            )

            # Create executor
            agent_executor = AgentExecutor(
                agent=agent, 
                tools=mcp_tools, 
                verbose=True
            )

            # Query your agent
            await agent_executor.ainvoke({
                "messages": [HumanMessage(content=
                    "What are the most trending discussions about AI today?"
                )]
            })

if __name__ == "__main__":
    asyncio.run(main())
```

<Check>
Your LangChain agent is now powered by real-time social media context from Membit!
</Check>
</Step>
</Steps>

## Complete Example

Here's a full working example with enhanced functionality:

<CodeGroup>
```python Basic Integration
import asyncio

from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.chat_models import init_chat_model
from langchain.schema import HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_mcp_adapters.tools import load_mcp_tools
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# Initialize LLM
llm = init_chat_model(
    model="gpt-4o",
    model_provider="openai",
)

server_params = StdioServerParameters(
    command="npx",
    args=[
            "mcp-remote",
            # Replace `<your-api-key>` with your actual Membit API key.
            "https://mcp.membit.ai/mcp/?Membit-Api-Key=<your-api-key>",
        ],
)

prompt = ChatPromptTemplate.from_messages([
    (
        "system",
        "You are a social media analyst with access to real-time data. "
        "Make sure you utilize membit tools to get the most trending data."
    ),
    MessagesPlaceholder(variable_name="messages"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

async def main():
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            mcp_tools = await load_mcp_tools(session)
            
            agent = create_openai_tools_agent(
                llm=llm, 
                tools=mcp_tools, 
                prompt=prompt
            )
            
            agent_executor = AgentExecutor(
                agent=agent, 
                tools=mcp_tools, 
                verbose=True
            )
            
            user_input = (
                "What are the most trending discussions today related to Bitcoin? "
                "Give me the best conversations to follow with URLs."
            )
            
            await agent_executor.ainvoke({
                "messages": [HumanMessage(content=user_input)]
            })
            

if __name__ == "__main__":
    asyncio.run(main())
```
</CodeGroup>

## Best Practices

<Card title="Optimize Your Prompts" icon="lightbulb">
- Include specific instructions about which Membit tools to use in your system prompt
- Guide the agent to use `cluster_search` first for trend discovery
- Encourage source attribution and URL inclusion in responses
</Card>

<Card title="Handle MCP Connections" icon="network-wired">
- Always use async context managers for MCP connections
- Initialize the session before loading tools
- Handle connection failures gracefully with try-catch blocks
</Card>

## Troubleshooting

<AccordionGroup>
<Accordion title="MCP Connection Issues">
**Problem**: Cannot connect to Membit MCP server

**Solutions**:
- Verify `mcp-remote` is installed: `npm list -g mcp-remote`
- Check your API key
- Ensure Node.js is properly installed and accessible
- Try running `npx mcp-remote` directly to test connectivity
</Accordion>

<Accordion title="Tool Loading Failures">
**Problem**: `load_mcp_tools` returns empty or fails

**Solutions**:
- Initialize the MCP session before loading tools
- Check network connectivity and firewall settings
- Verify your Membit API credentials are valid
- Look for error messages in the MCP connection logs
</Accordion>

<Accordion title="Agent Execution Errors">
**Problem**: Agent fails to execute or use tools properly

**Solutions**:
- Check that tools are properly passed to both agent and executor
- Ensure your prompt includes the required message placeholders
- Verify the LLM has sufficient context window for tool responses
- Test with simpler queries first
</Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
<Card title="Explore Use Cases" icon="compass" href="/use-cases">
  Discover practical applications for Membit in different industries and scenarios.
</Card>

<Card title="API Reference" icon="code" href="/api-usage/python">
  Dive deeper into Membit's Python API for custom implementations.
</Card>

<Card title="Get Support" icon="life-ring" href="/misc/faqs">
  Find answers to common questions or reach out for help.
</Card>
</CardGroup>
